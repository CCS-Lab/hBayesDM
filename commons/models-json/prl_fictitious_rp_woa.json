{
  "task_name": {
    "code": "prl",
    "desc": "Probabilistic Reversal Learning Task",
    "cite": []
  },
  "model_name": {
    "code": "fictitious_rp_woa",
    "desc": "Fictitious Update Model, with separate learning rates for positive and negative prediction error (PE), without alpha (indecision point)",
    "cite": [
      "Glascher, J., Hampton, A. N., & O'Doherty, J. P. (2009). Determining a Role for Ventromedial Prefrontal Cortex in Encoding Action-Based Value Signals During Reward-Related Decision Making. Cerebral Cortex, 19(2), 483-495. http://doi.org/10.1093/cercor/bhn098",
      "Ouden, den, H. E. M., Daw, N. D., Fernandez, G., Elshout, J. A., Rijpkema, M., Hoogman, M., et al. (2013). Dissociable Effects of Dopamine and Serotonin on Reversal Learning. Neuron, 80(4), 1090-1100. http://doi.org/10.1016/j.neuron.2013.08.030"
    ]
  },
  "model_type": {
    "code": "",
    "desc": "Hierarchical"
  },
  "notes": [],
  "contributors": [
    {
      "name": "Jaeyeong Yang (for model-based regressors)",
      "email": "jaeyeong.yang1125@gmail.com",
      "link": "https://ccs-lab.github.io/team/jaeyeong-yang/"
    },
    {
      "name": "Harhim Park (for model-based regressors)",
      "email": "hrpark12@gmail.com",
      "link": "https://ccs-lab.github.io/team/harhim-park/"
    }
  ],
  "data_columns": {
    "subjID": "A unique identifier for each subject in the data-set.",
    "choice": "Integer value representing the option chosen on that trial: 1 or 2.",
    "outcome": "Integer value representing the outcome of that trial (where reward == 1, and loss == -1)."
  },
  "parameters": {
    "eta_pos": {
      "desc": "learning rate, +PE",
      "info": [0, 0.5, 1]
    },
    "eta_neg": {
      "desc": "learning rate, -PE",
      "info": [0, 0.5, 1]
    },
    "beta": {
      "desc": "inverse temperature",
      "info": [0, 1, 10]
    }
  },
  "regressors": {
    "ev_c": 2,
    "ev_nc": 2,
    "pe_c": 2,
    "pe_nc": 2,
    "dv": 2
  },
  "postpreds": ["y_pred"],
  "additional_args": []
}
