task_name:
  code: banditNarm
  desc: N-Armed Bandit Task
  cite:
model_name:
  code: 2par_lapse
  desc: 3 Parameter Model, without C (choice perseveration), R (reward sensitivity),
    and P (punishment sensitivity). But with xi (noise)
  cite:
  - Aylward, Valton, Ahn, Bond, Dayan, Roiser, & Robinson (2018) Altered decision-making
    under uncertainty in unmedicated mood and anxiety disorders. PsyArxiv. 10.31234/osf.io/k5b8m
model_type:
  code:
  desc: Hierarchical
notes:
contributors:
  - name: Cheol Jun Cho
    email: cjfwndnsl@gmail.com
    link: https://github.com/cheoljun95
data_columns:
  subjID: A unique identifier for each subject in the data-set.
  choice: 'Integer value representing the option chosen on the given trial: 1, 2,
    3, ... N.'
  gain: Floating point value representing the amount of currency won on the given
    trial (e.g. 50, 100).
  loss: Floating point value representing the amount of currency lost on the given
    trial (e.g. 0, -50).
parameters:
  Arew:
    desc: reward learning rate
    info: [0, 0.1, 1]
  Apun:
    desc: punishment learning rate
    info: [0, 0.1, 1]
  xi:
    desc: noise
    info: [0, 0.1, 1]
regressors:
postpreds:
- y_pred
additional_args:
  - code: Narm
    default: null
    desc:
      Number of arms used in Multi-armed Bandit Task If not given,
      the number of unique choice will be used.
