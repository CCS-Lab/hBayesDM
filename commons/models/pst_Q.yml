task_name:
  code: pst
  desc: Probabilistic Selection Task
  cite:
model_name:
  code: Q
  desc: Q Learning Model
  cite:
  - Frank, M. J., Moustafa, A. A., Haughey, H. M., Curran, T., & Hutchison, K. E.
    (2007). Genetic triple dissociation reveals multiple roles for dopamine in reinforcement
    learning. Proceedings of the National Academy of Sciences, 104(41), 16311-16316.
model_type:
  code:
  desc: Hierarchical
notes:
contributors:
- name: David Munoz Tord
  email: david.munoztord@unige.ch
  link: https://david-munoztord.com/
data_columns:
  subjID: A unique identifier for each subject in the data-set.
  type: Two-digit number indicating which pair of stimuli were presented for that
    trial, e.g. 12, 34, or 56. The digit on the left (tens-digit) indicates the presented
    stimulus for option1, while the digit on the right (ones-digit) indicates that
    for option2. Code for each stimulus type (1~6) is defined as for 80\% (type 1),
    20\% (type 2), 70\% (type 3), 30\% (type 4), 60\% (type 5), 40\% (type 6). The
    modeling will still work even if different probabilities are used for the stimuli;
    however, the total number of stimuli should be less than or equal to 6.
  choice: Whether the subject chose the left option (option1) out of the given two
    options (i.e. if option1 was chosen, 1; if option2 was chosen, 0).
  reward: Amount of reward earned as a result of the trial.
parameters:
  alpha:
    desc: learning rate
    info: [0, 0.5, 1]
  beta:
    desc: inverse temperature
    info: [0, 1, 10]
regressors:
postpreds:
- y_pred
additional_args:
