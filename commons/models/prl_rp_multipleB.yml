task_name:
  code: prl
  desc: Probabilistic Reversal Learning Task
  cite:
model_name:
  code: rp
  desc: Reward-Punishment Model
  cite:
    - Ouden, den, H. E. M., Daw, N. D., Fernandez, G., Elshout, J. A., Rijpkema, M.,
      Hoogman, M., et al. (2013). Dissociable Effects of Dopamine and Serotonin on Reversal
      Learning. Neuron, 80(4), 1090-1100. https://doi.org/10.1016/j.neuron.2013.08.030
model_type:
  code: multipleB
  desc: Multiple-Block Hierarchical
notes:
contributors:
  - name: Jaeyeong Yang (for model-based regressors)
    email: jaeyeong.yang1125@gmail.com
    link: https://ccs-lab.github.io/team/jaeyeong-yang/
  - name: Harhim Park (for model-based regressors)
    email: hrpark12@gmail.com
    link: https://ccs-lab.github.io/team/harhim-park/
data_columns:
  subjID: A unique identifier for each subject in the data-set.
  block: A unique identifier for each of the multiple blocks within each subject.
  choice: "Integer value representing the option chosen on that trial: 1 or 2."
  outcome:
    Integer value representing the outcome of that trial (where reward == 1,
    and loss == -1).
parameters:
  Apun:
    desc: punishment learning rate
    info: [0, 0.1, 1]
  Arew:
    desc: reward learning rate
    info: [0, 0.1, 1]
  beta:
    desc: inverse temperature
    info: [0, 1, 10]
regressors:
  ev_c: 3
  ev_nc: 3
  pe: 3
postpreds:
  - y_pred
additional_args:
