task_name:
  code: pstRT
  desc: Probabilistic Selection Task (with RT data)
  cite:
  - 'Frank, M. J., Santamaria, A., O''Reilly, R. C., & Willcutt, E. (2007). Testing computational models of dopamine and noradrenaline dysfunction in attention deficit/hyperactivity disorder. Neuropsychopharmacology, 32(7), 1583-1599.'
  - 'Frank, M. J., Seeberger, L. C., & O''reilly, R. C. (2004). By carrot or by stick: cognitive reinforcement learning in parkinsonism. Science, 306(5703), 1940-1943.'
model_name:
  code: ddm
  desc: Drift Diffusion Model
  cite:
  - Pedersen, M. L., Frank, M. J., & Biele, G. (2017). The drift diffusion model as the choice rule in reinforcement learning. Psychonomic bulletin & review, 24(4), 1234-1251.  
model_type:
  code: ''
  desc: Hierarchical
data_columns:
  subjID: A unique identifier for each subject in the data-set.  # Required
  cond: Integer value representing the task condition of the given trial (AB == 1, CD == 2, EF == 3).
  choice: Integer value representing the option chosen on the given trial (1 or 2).
  RT: Float value representing the time taken for the response on the given trial.
parameters:
  a:
    desc: boundary separation
    info: [0, 1.8, 'Inf']
  tau:
    desc: non-decision time
    info: [0, 0.3, 'Inf']
  d1:
    desc: drift rate scaling
    info: ['-Inf', 0.8, 'Inf']
  d2:
    desc: drift rate scaling
    info: ['-Inf', 0.4, 'Inf']
  d3:
    desc: drift rate scaling
    info: ['-Inf', 0.3, 'Inf']
regressors:
postpreds:
- choice_os
- RT_os
additional_args:
- code: RTbound
  default: 0.1
  desc: Floating point value representing the lower bound (i.e., minimum allowed)
    reaction time. Defaults to 0.1 (100 milliseconds).
contributors:
- name: Hoyoung Doh
  email: hoyoung.doh@gmail.com
  link: https://hydoh.github.io/
- name: Sanghoon Kang
  email: sanghoon.kang@yale.edu
  link: https://medicine.yale.edu/lab/goldfarb/profile/sanghoon_kang/
- name: Jihyun K. Hur
  email: jihyun.hur@yale.edu
  link: https://jihyuncindyhur.github.io/