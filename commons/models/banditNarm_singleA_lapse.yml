task_name:
  code: banditNarm
  desc: N-Armed Bandit Task
  cite:
model_name:
  code: singleA_lapse
  desc: 4 Parameter Model, without C (choice perseveration) but with xi (noise). Single
    learning rate both for R and P.
  cite:
  - Aylward, Valton, Ahn, Bond, Dayan, Roiser, & Robinson (2018) Altered decision-making
    under uncertainty in unmedicated mood and anxiety disorders. PsyArxiv. 10.31234/osf.io/k5b8m
model_type:
  code:
  desc: Hierarchical
notes:
contributors:
  - name: Cheol Jun Cho
    email: cjfwndnsl@gmail.com
    link: https://github.com/cheoljun95
data_columns:
  subjID: A unique identifier for each subject in the data-set.
  choice: 'Integer value representing the option chosen on the given trial: 1, 2,
    3, ... N.'
  gain: Floating point value representing the amount of currency won on the given
    trial (e.g. 50, 100).
  loss: Floating point value representing the amount of currency lost on the given
    trial (e.g. 0, -50).
parameters:
  A:
    desc: learning rate
    info: [0, 0.1, 1]
  R:
    desc: reward sensitivity
    info: [0, 1, 30]
  P:
    desc: punishment sensitivity
    info: [0, 1, 30]
  xi:
    desc: noise
    info: [0, 0.1, 1]
regressors:
postpreds:
- y_pred
additional_args:
  - code: Narm
    default: null
    desc:
      Number of arms used in Multi-armed Bandit Task If not given,
      the number of unique choice will be used.