{
  "task_name": {
    "code": "pst",
    "desc": "Probabilistic Selection Task",
    "cite": []
  },
  "model_name": {
    "code": "gainloss_Q",
    "desc": "Gain-Loss Q Learning Model",
    "cite": [
      "Frank, M. J., Moustafa, A. A., Haughey, H. M., Curran, T., & Hutchison, K. E. (2007). Genetic triple dissociation reveals multiple roles for dopamine in reinforcement learning. Proceedings of the National Academy of Sciences, 104(41), 16311-16316."
    ]
  },
  "model_type": {
    "code": "",
    "desc": "Hierarchical"
  },
  "notes": [],
  "contributors": [
    {
      "name": "Jaeyeong Yang",
      "email": "jaeyeong.yang1125@gmail.com",
      "link": "https://ccs-lab.github.io/team/jaeyeong-yang/"
    }
  ],
  "data_columns": {
    "subjID": "A unique identifier for each subject in the data-set.",
    "type": "Two-digit number indicating which pair of stimuli were presented for that trial, e.g. 12, 34, or 56. The digit on the left (tens-digit) indicates the presented stimulus for option1, while the digit on the right (ones-digit) indicates that for option2. Code for each stimulus type (1~6) is defined as below:\n\n        ===== ======== ==================\n        Code  Stimulus Probability to win\n        ===== ======== ==================\n          1   A        80%\n          2   B        20%\n          3   C        70%\n          4   D        30%\n          5   E        60%\n          6   F        40%\n        ===== ======== ==================\n\n        The modeling will still work even if different probabilities are used for the stimuli; however, the total number of stimuli should be less than or equal to 6.",
    "choice": "Whether the subject chose the left option (option1) out of the given two options (i.e. if option1 was chosen, 1; if option2 was chosen, 0).",
    "reward": "Amount of reward earned as a result of the trial."
  },
  "parameters": {
    "alpha_pos": {
      "desc": "learning rate for positive feedbacks",
      "info": [0, 0.5, 1]
    },
    "alpha_neg": {
      "desc": "learning rate for negative feedbacks",
      "info": [0, 0.5, 1]
    },
    "beta": {
      "desc": "inverse temperature",
      "info": [0, 1, 10]
    }
  },
  "regressors": {},
  "postpreds": ["y_pred"],
  "additional_args": []
}
