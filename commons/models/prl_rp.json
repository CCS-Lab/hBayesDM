{
  "task_name": {
    "code": "prl",
    "desc": "Probabilistic Reversal Learning Task",
    "cite": []
  },
  "model_name": {
    "code": "rp",
    "desc": "Reward-Punishment Model",
    "cite": [
      "Ouden, den, H. E. M., Daw, N. D., Fernandez, G., Elshout, J. A., Rijpkema, M., Hoogman, M., et al. (2013). Dissociable Effects of Dopamine and Serotonin on Reversal Learning. Neuron, 80(4), 1090-1100. http://doi.org/10.1016/j.neuron.2013.08.030"
    ]
  },
  "model_type": {
    "code": "",
    "desc": "Hierarchical"
  },
  "notes": [],
  "contributors": [
    {
      "name": "Jaeyeong Yang (for model-based regressors)",
      "email": "jaeyeong.yang1125@gmail.com",
      "link": "https://ccs-lab.github.io/team/jaeyeong-yang/"
    },
    {
      "name": "Harhim Park (for model-based regressors)",
      "email": "hrpark12@gmail.com",
      "link": "https://ccs-lab.github.io/team/harhim-park/"
    }
  ],
  "data_columns": {
    "subjID": "A unique identifier for each subject in the data-set.",
    "choice": "Integer value representing the option chosen on that trial: 1 or 2.",
    "outcome": "Integer value representing the outcome of that trial (where reward == 1, and loss == -1)."
  },
  "parameters": {
    "Apun": {
      "desc": "punishment learning rate",
      "info": [0, 0.1, 1]
    },
    "Arew": {
      "desc": "reward learning rate",
      "info": [0, 0.1, 1]
    },
    "beta": {
      "desc": "inverse temperature",
      "info": [0, 1, 10]
    }
  },
  "regressors": {
    "ev_c": 2,
    "ev_nc": 2,
    "pe": 2
  },
  "postpreds": ["y_pred"],
  "additional_args": []
}
