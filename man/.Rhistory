Z <-X[,rownames(Sigma)]
sum(diag(Z %*% Sigma %*% t(Z)))/n
}))
Se <- attr(Sigma.list, "sc")^2
total.var <- Sf + Sl + Se + Sd
(Rsq.m <- Sf / total.var)
(Rsq.c <- (Sf + Sl) / total.var)
Sd <- 0
total.var <- Sf + Sl + Se + Sd
(Rsq.m <- Sf / total.var)
(Rsq.c <- (Sf + Sl) / total.var)
rm(X, n, Beta, Sf, Sigma.list, Sl, Se, Sd, total.var, Rsq.m, Rsq.c)
X <- model.matrix(orangemod.ri)
n <- nrow(X)
Beta <- fixef(orangemod.ri)
Sf <- var(X %*% Beta)
Sigma.list <- VarCorr(orangemod.ri)
Sl <-
sum(
sapply(Sigma.list,
function(Sigma)
{
Z <-X[,rownames(Sigma)]
sum(diag(Z %*% Sigma %*% t(Z)))/n
}))
Se <- attr(Sigma.list, "sc")^2
Sd <- 0
total.var <- Sf + Sl + Se + Sd
(Rsq.m <- Sf / total.var)
(Rsq.c <- (Sf + Sl) / total.var)
citation(package = "base", lib.loc = NULL)
library(rstan)
Sys.setenv(MAKEFLAGS = "-j4")
source('http://mc-stan.org/rstan/install.R', echo = TRUE, max.deparse.length = 2000)
install_rstan()
library(rstan)
install.packages(c("Boom", "BoomSpikeSlab", "bsts", "manipulate"))
install.packages(c("bdsmatrix", "BH", "boot", "car", "caTools", "class", "cluster", "coda", "codetools", "colorspace", "compute.es", "corrgram", "DEoptimR", "digest", "doBy", "e1071", "fBasics", "foreign", "formatR", "Formula", "geoR", "gplots", "gss", "hexbin", "highr", "Hmisc", "KernSmooth", "knitr", "labeling", "lattice", "lme4", "manipulate", "markdown", "MASS", "Matrix", "mclust", "mgcv", "mime", "minqa", "mvtnorm", "ncvreg", "nlme", "nnet", "pbivnorm", "pcaPP", "pitchRx", "plotrix", "psych", "qgraph", "R.matlab", "R.methodsS3", "R.oo", "R.utils", "RandomFields", "raster", "Rcmdr", "RColorBrewer", "Rcpp", "RcppEigen", "RCurl", "reshape2", "rgl", "rjags", "rms", "robustbase", "rockchalk", "rpart", "rrcov", "sandwich", "seriation", "sp", "SparseM", "spatial", "splancs", "survival", "tcltk2", "timeDate", "timeSeries", "TSP"), lib="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
library(glmnet)
library(rstan)
load("/Users/wahn/Dropbox/InternshipStuff/UICinternship/HIV_Addictions/IGT_analysis/ABCD/heroin_elasticNet_CVresults_numReg_57_numGroups4_numAlpha10_numIter1000.Rdata")
rm(list=ls())      # clear workspace
library(R.matlab)  # to save output as a mat.file
library(glmnet)    # penalized regression
library(ggplot2)
library(mail) # to send emails
library(e1071)
library(pROC)   # multi-class ROC AUC
library(doBy)
load("/Users/wahn/Dropbox/InternshipStuff/UICinternship/HIV_Addictions/IGT_analysis/ABCD/heroin_elasticNet_CVresults_numReg_57_numGroups4_numAlpha10_numIter1000.Rdata")
lasso_cv_glmnet_best
install.packages("sparcl")
library(sparcl)
?sparcl
??sparcl
sparcl
?KMeansSparseCluster
sparClResult = KMeansSparseCluster(allDat_noNA)
sparClResult = KMeansSparseCluster(allDat_noNA, 4)
sparClResult
plot(sparClResult)
quartz();plot(sparClResult)
quartz()
plot(sparClResult)
sparClResult
sparClResult = KMeansSparseCluster.permute(allDat_noNA, 4)
km.out = KMeansSparseCluster(allDat_noNA, 4, wbounds = sparClResult$bestw)
km.out
plot(km.out)
quartz(); plot(km.out)
set.seed(11)
x <- matrix(rnorm(50*70),ncol=70)
x[1:25,1:20] <- x[1:25,1:20]+1
x <- scale(x, TRUE, TRUE)
# choose tuning parameter
km.perm <- KMeansSparseCluster.permute(x,K=2,wbounds=seq(3,7,len=15),nperms=5)
print(km.perm)
plot(km.perm)
# run sparse k-means
km.out <- KMeansSparseCluster(x,K=2,wbounds=km.perm$bestw)
print(km.out)
plot(km.out)
# run sparse k-means for a range of tuning parameter values
km.out <- KMeansSparseCluster(x,K=2,wbounds=seq(1.3,4,len=8))
print(km.out)
plot(km.out)
quartz();plot(km.out)
km.out <- KMeansSparseCluster(x,K=2,wbounds=km.perm$bestw)
print(km.out)
plot(km.out)
quartz();plot(km.out)
set.seed(1)
x <- matrix(rnorm(100*50),ncol=50)
y <- c(rep(1,50),rep(2,50))
x[y==1,1:25] <- x[y==1,1:25]+2
# Do tuning parameter selection for sparse hierarchical clustering
perm.out <- HierarchicalSparseCluster.permute(x, wbounds=c(1.5,2:6),
nperms=5)
print(perm.out)
plot(perm.out)
quartz();
plot(perm.out)
sparsehc <- HierarchicalSparseCluster(dists=perm.out$dists,
wbound=perm.out$bestw, method="complete")
# faster than   sparsehc <- HierarchicalSparseCluster(x=x,wbound=perm.out$bestw, method="complete")
par(mfrow=c(1,2))
plot(sparsehc)
library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
model <- stan_demo()
library(rstan)
# elasticNet_JasminR01.R
# v1: uses R01_Apr18_2012_elasticNet_v2.csv
# v2: uses R01_June2014_allData_elasticNet.csv
# v3: uses R01_Impulsivity_variables_regression_Young_noDrugVariables.csv, Oct 10, 2014
# v3_continuous: predict N_sx_...
# v4: multiple iterations ... & figures
# v5: using reduced data base.. v4...
# v6: different labels when excluding a pure group
#     different file names for excluding/including a pure group
# v7: with dataset v6.. allows removing total scores and others..
#     poly is an option now
#     Improved color scheme!! (1/16/2015)
# v8: out-of-sample option... save files with v8, uses data v7, separately for amph and heroin predictions
#
# v4: added more PRL measures and removes demographic variables
# v5: add back demographic variables
# v6: behavDat & useDat include "Race" now... also include more variables for Tables 1 and 2
# v6_.._multiTestSets: different combinations of training/test sets
library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
parallel::detectCores()
s_r = 400:50:2000
s_r = 400:2000:50
s_r = seq(200, 2000, by=50)
s_r
l_r = seq(200, 2000, by=50)
s_r %*% l_r
s_r %o% l_r
combn(c(1,1,1,1,2,2,2,3,3,4), 3, tabulate, nbins = 4)
combn(3, 2)
expand.grid(s_r, l_r)
s_r = seq(200, 2000, by=100)
l_r = seq(200, 2000, by=100)
expand.grid(s_r, l_r)
s_r = seq(200, 2000, by=200)
l_r = seq(200, 2000, by=200)
expand.grid(s_r, l_r)
expand.grid(s_r, l_r, s_r)
s_t = 0
l_t = c("3days", "1week", "2week", "3week", "1month", "2month", "3month", "6month", "1yr", "3yr", "10yr")
s_r = seq(200, 2000, by=200)
l_r = seq(200, 2000, by=200)
expand.grid(s_t, l_t, s_r, l_r)
source('~/Dropbox/ADO_DD/ado_parameter_cs.R')
s
source('~/Dropbox/ADO_DD/ado_parameter_cs.R')
gamma_all = seq(0.0005, 0.1, by = 0.0005);
gamma_all
source('~/Dropbox/ADO_DD/ado_parameter_cs.R')
plot()
plot(1, 1)
source('~/Dropbox/ADO_DD/ado_parameter_cs.R')
graphics.off()
source('~/Dropbox/ADO_DD/ado_parameter_cs.R')
source('~/Dropbox/ADO_DD/ado_parameter_hyp.R')
plot(0, 0, xlim=c(0,520), ylim=c(0,1), type="l",
main = "Hyperbolic (1 par), k from 0.0001 to 0.5, by 0.001")
source('~/Dropbox/ADO_DD/ado_parameter_hyp.R')
source('~/Dropbox/ADO_DD/ado_parameter_cs.R')
gIdx=1
quartz()
plot(0, 0, xlim=c(0,520), ylim=c(0,1), type="l",
main = "CS (2 pars), gamma from 0.0005 to 0.3, s from 0.05 to 3.0")
gamma = gamma_all[gIdx]
for (sIdx in 1:length(s_all)) {
s = s_all[sIdx]
sv = exp(-1 * (gamma * delay)^s );
lines(delay, sv, type="l",xlim=c(0,520), ylim=c(0,1), ylab="", xlab="", col=gIdx)
}
gamma_all = seq(0.0005, 0.2, by = 0.01);
s_all = seq(0.005, 3.0, by = 0.05)
quartz()
plot(0, 0, xlim=c(0,520), ylim=c(0,1), type="l",
main = "CS (2 pars), gamma from 0.0005 to 0.3, s from 0.05 to 3.0")
gIdx
gamma = gamma_all[gIdx]
for (sIdx in 1:length(s_all)) {
s = s_all[sIdx]
sv = exp(-1 * (gamma * delay)^s );
lines(delay, sv, type="l",xlim=c(0,520), ylim=c(0,1), ylab="", xlab="", col=gIdx)
}
s_all = seq(0.0005, 3.0, by = 0.05)
quartz()
plot(0, 0, xlim=c(0,520), ylim=c(0,1), type="l",
main = "CS (2 pars), gamma from 0.0005 to 0.3, s from 0.05 to 3.0")
gamma = gamma_all[gIdx]
for (sIdx in 1:length(s_all)) {
s = s_all[sIdx]
sv = exp(-1 * (gamma * delay)^s );
lines(delay, sv, type="l",xlim=c(0,520), ylim=c(0,1), ylab="", xlab="", col=gIdx)
}
s_all = seq(0.0005, 5.0, by = 0.05)
gamma = gamma_all[gIdx]
for (sIdx in 1:length(s_all)) {
s = s_all[sIdx]
sv = exp(-1 * (gamma * delay)^s );
lines(delay, sv, type="l",xlim=c(0,520), ylim=c(0,1), ylab="", xlab="", col=gIdx)
}
quartz()
plot(0, 0, xlim=c(0,520), ylim=c(0,1), type="l",
main = "CS (2 pars), gamma from 0.0005 to 0.3, s from 0.05 to 3.0")
gamma = gamma_all[gIdx]
for (sIdx in 1:length(s_all)) {
s = s_all[sIdx]
sv = exp(-1 * (gamma * delay)^s );
lines(delay, sv, type="l",xlim=c(0,520), ylim=c(0,1), ylab="", xlab="", col=gIdx)
}
s_all = seq(0.0005, 1.0, by = 0.05)
quartz()
plot(0, 0, xlim=c(0,520), ylim=c(0,1), type="l",
main = "CS (2 pars), gamma from 0.0005 to 0.3, s from 0.05 to 3.0")
gamma = gamma_all[gIdx]
for (sIdx in 1:length(s_all)) {
s = s_all[sIdx]
sv = exp(-1 * (gamma * delay)^s );
lines(delay, sv, type="l",xlim=c(0,520), ylim=c(0,1), ylab="", xlab="", col=gIdx)
}
s_all = seq(0.0005, 2.0, by = 0.05)
gamma = gamma_all[gIdx]
for (sIdx in 1:length(s_all)) {
s = s_all[sIdx]
sv = exp(-1 * (gamma * delay)^s );
lines(delay, sv, type="l",xlim=c(0,520), ylim=c(0,1), ylab="", xlab="", col=gIdx)
}
gamma_all = seq(0.0005, 0.2, by = 0.01);
s_all = seq(0.0005, 2.0, by = 0.05)
quartz()
plot(0, 0, xlim=c(0,520), ylim=c(0,1), type="l",
main = "CS (2 pars), gamma from 0.0005 to 0.3, s from 0.05 to 3.0")
gamma = gamma_all[gIdx]
for (sIdx in 1:length(s_all)) {
s = s_all[sIdx]
sv = exp(-1 * (gamma * delay)^s );
lines(delay, sv, type="l",xlim=c(0,520), ylim=c(0,1), ylab="", xlab="", col=gIdx)
}
gamma
gamma = 0.1
plot(0, 0, xlim=c(0,520), ylim=c(0,1), type="l",
main = "CS (2 pars), gamma from 0.0005 to 0.3, s from 0.05 to 3.0")
gamma = gamma_all[gIdx]
for (sIdx in 1:length(s_all)) {
s = s_all[sIdx]
sv = exp(-1 * (gamma * delay)^s );
lines(delay, sv, type="l",xlim=c(0,520), ylim=c(0,1), ylab="", xlab="", col=gIdx)
}
gamma = 0.1
plot(0, 0, xlim=c(0,520), ylim=c(0,1), type="l",
main = "CS (2 pars), gamma from 0.0005 to 0.3, s from 0.05 to 3.0")
for (sIdx in 1:length(s_all)) {
s = s_all[sIdx]
sv = exp(-1 * (gamma * delay)^s );
lines(delay, sv, type="l",xlim=c(0,520), ylim=c(0,1), ylab="", xlab="", col=gIdx)
}
gamma = 0.2
plot(0, 0, xlim=c(0,520), ylim=c(0,1), type="l",
main = "CS (2 pars), gamma from 0.0005 to 0.3, s from 0.05 to 3.0")
for (sIdx in 1:length(s_all)) {
s = s_all[sIdx]
sv = exp(-1 * (gamma * delay)^s );
lines(delay, sv, type="l",xlim=c(0,520), ylim=c(0,1), ylab="", xlab="", col=gIdx)
}
source('~/Dropbox/ADO_DD/ado_parameter_cs.R')
source('~/Dropbox/ADO_DD/ado_parameter_cs.R', echo=TRUE)
source('~/Dropbox/ADO_DD/ado_parameter_cs.R')
?seq
seq(0.005, 0.2, length.out = 20)
gamma_all = seq(0.0005, 0.2, by = 0.001);
gamma_all
source('~/Dropbox/ADO_DD/ado_parameter_cs.R')
gamma_all = c( seq(0.005, 0.01 by=0.001), seq(0.01, 0.2, by = 0.01) )
gamma_all = c( seq(0.005, 0.01, by=0.001), seq(0.01, 0.2, by = 0.01) )
length(gamma_all)
source('~/Dropbox/ADO_DD/ado_parameter_cs.R')
gamma_all
source('~/Dropbox/ADO_DD/ado_parameter_cs.R')
seq(0.005, 0.01, by=0.001)
rm(list=ls())
#delay = c(0.5, 1, 2, 3, 4, 8, 12, 26, 52, 156, 520);
delay = seq(0, 520, by = 1)
# gamma_all = seq(0.0005, 0.1, by = 0.0005);
# s_all = seq(0.05, 2.0, by = 0.05)
gamma_all = seq(0.0005, 0.2, by = 0.001);
#gamma_all = c( seq(0.005, 0.01, by=0.001), seq(0.01, 0.2, by = 0.01) )
s_all = seq(0.05, 2.0, by = 0.05)
quartz()
plot(0, 0, xlim=c(0,520), ylim=c(0,1), type="l",
main = "CS (2 pars), gamma from 0.0005 to 0.3, s from 0.05 to 3.0")
gIdx=1
gamma = gamma_all[gIdx]
gamma
source('~/Dropbox/ADO_DD/ado_parameter_cs.R')
lengthg(gamma_all)
length(gamma_all)
source('~/Dropbox/ADO_DD/ado_parameter_cs.R')
s_all = seq(0.05, 2.0, by = 0.1)
length(s_all)
iinstall.packages(edgeR)
iinstall.packages("edgeR")
source("https://bioconductor.org/biocLite.R")
biocLite("edgeR")
library(edgeR)
x = read.delim("fileofcounts.txt")
library(baySeq)
install.packages(baySeq)
source("https://bioconductor.org/biocLite.R")
biocLite("baySeq")
library(baySeq)
load("mobData.RData")
head(mobData)
load("https://bios221.stanford.edu/data/mobData.RData")
?load
load(url("https://bios221.stanford.edu/data/mobData.RData"))
head(mobData)
mobDataGroups <- c("MM", "MM", "WM", "WM", "WW", "WW")
data(mobAnnotation)
head(mobAnnotation)
d <- DGEList(counts=mobData,group=factor(mobDataGroups))
d
d.full <- d # keep the old one in case we mess up
head(d$counts)
head(cpm(d))
apply(d$counts, 2, sum) # total gene counts per sample
keep <- rowSums(cpm(d)>100) >= 2
d <- d[keep,]
dim(d)
d$samples$lib.size <- colSums(d$counts)
d$samples
d <- calcNormFactors(d)
d
dim(d)
plotMDS(d, method="bcv", col=as.numeric(d$samples$group))
d
d$samples
d
d[[1]]
dim(d[[1]])
dim(d[[2]])
dim(d[[3]])
dim
d
legend("bottomleft", as.character(unique(d$samples$group)), col=1:3, pch=20)
d1 <- estimateCommonDisp(d, verbose=T)
names(d1)
d1 <- estimateTagwiseDisp(d1)
plotBCV(d1)
install.packages("PMA")
library(PMA)
install.packages("impute")
source("https://bioconductor.org/biocLite.R")
biocLite("impute")
source("https://bioconductor.org/biocLite.R")
biocLite("impute")
library(PMA)
?"PMA-package"
??"PMA-package"
data(breastdata)
attach(breastdata)
PlotCGH(dna[,1], chrom=chrom, main="Sample 1", nuc=nuc)
detach(breastdata)
dim(dna)
dna
breastdata
length(breastdata)
data(breastdata)
attach(breastdata)
PlotCGH(dna[,1], chrom=chrom, main="Sample 1", nuc=nuc)
dim(dna)
head(dna)
clc
library(RWiener)
set.seed(0)dat <- rwiener(n=100, alpha=2, tau=.3, beta=.5, delta=.5)
set.seed(0)
dat <- rwiener(n=100, alpha=2, tau=.3, beta=.5, delta=.5)
dat
plot(dat)
dwiener(dat$q[1], alpha=2, tau=.3, beta=.5, delta=.5, resp=dat$resp[1], give_log=FALSE)
curve(dwiener(x, 2, .3, .5, .5, rep("upper", length(x))),      xlim=c(0,3), main="Density of upper responses",      ylab="density", xlab="quantile")
x
pwiener(dat$q[1], alpha=2, tau=.3, beta=.5, delta=.5, resp=dat$resp[1])
x <- c(2, .3, .5, .5)
wiener_likelihood(x=x, dat=dat)
dat
table(dat$resp)
hist(dat$q)
hist(dat$q, breaks=20)
dat <- rwiener(n=1000, alpha=2, tau=.3, beta=.5, delta=.5)
hist(dat$q, breaks=20)
optim1 <- optim(c(1, .1, .1, 1), wiener_deviance, dat=dat, method="Nelder-Mead")
optim1
#dat <- rwiener(n=100, alpha=2, tau=.3, beta=.5, delta=.5)
wiener_likelihood
dwiener
optim2 <- optim(optim1[["par"]], wiener_deviance, dat=dat, method="BFGS", hessian=TRUE)
optim1
optim2
nlm1 <- nlm(p=c(1, .1, .1, 1), f=wiener_deviance, dat=dat)
nlm1
when excluding a pure group
#     different file names for excluding/including a pure group
# v7: with dataset v6.. allows removing total scores and others..
#     poly is an option now
#     Improved color scheme!! (1/16/2015)
# v8: out-of-sample option... save files with v8, uses data v7, separately for amph and heroin predictions
#     binary: does logistic regression following Alex Todorov's suggestions.
#     removes HRBS-S from a list of regressors
# v9: don't use HRBS for sure. Exclude DRD_S_M
#     add Lane Omission error!
# v10: remove demographic variables
# v11: include demographic but exclude handedness....
# v12: exclude 5 bad subjects
# v13: try comparing pur
3487+6667
3487+6667+30
1000/30
1000/60
install.packages("twitteR")
library(twitteR)
keyword = "computational"
curri<-searchTwitter(keyword, lang="en", n=10000, since='2014-09-23')
?searchTwitteR
?searchTwitter
curri<-searchTwitter(keyword, n=10000, since='2014-09-23')
curri<-searchTwitter(keyword, n=10000)
curri<-searchTwitteR(keyword, n=10000)
install.packages("glmnet")
library(glmnet)
?glmnet
install.packages("h2o")
library(h20)
library(h2o)
??h2o
prostate
prosPath = system.file("extdata", "prostate.csv", package = "h2o")
prostate_df <- read.csv(prosPath)
prostate_df <- prostate_df[,-1]
summary(prostate_df)
set.seed(1234)
random_splits <- runif(nrow(prostate_df))
train_df <- prostate_df[random_splits < .5,]
dim(train_df)
validate_df <- prostate_df[random_splits >=.5,]
dim(validate_df)
install.packages('randomForest')
library(randomForest)
outcome_name <- 'CAPSULE'
feature_names <- setdiff(names(prostate_df), outcome_name)
set.seed(1234)
rf_model <- randomForest(x=train_df[,feature_names],
y=as.factor(train_df[,outcome_name]),
importance=TRUE, ntree=20, mtry = 3)
validate_predictions <- predict(rf_model, newdata=validate_df[,feature_names], type="prob")
library(pROC)
auc_rf = roc(response=as.numeric(as.factor(validate_df[,outcome_name]))-1,
predictor=validate_predictions[,2])
plot(auc_rf, print.thres = "best", main=paste('AUC:',round(auc_rf$auc[[1]],3)))
abline(h=1,col='blue')
abline(h=0,col='green')
localH2O = h2o.init()
prostate.hex<-as.h2o(train_df, destination_frame="train.hex")
prostate.dl = h2o.deeplearning(x = feature_names, training_frame = prostate.hex,
autoencoder = TRUE,
reproducible = T,
seed = 1234,
hidden = c(6,5,6), epochs = 50)
prostate.anon = h2o.anomaly(prostate.dl, prostate.hex, per_feature=FALSE)
head(prostate.anon)
err <- as.data.frame(prostate.anon)
plot(sort(err$Reconstruction.MSE), main='Reconstruction Error')
train_df_auto <- train_df[err$Reconstruction.MSE < 0.1,]
set.seed(1234)
rf_model <- randomForest(x=train_df_auto[,feature_names],
y=as.factor(train_df_auto[,outcome_name]),
importance=TRUE, ntree=20, mtry = 3)
validate_predictions_known <- predict(rf_model, newdata=validate_df[,feature_names], type="prob")
auc_rf = roc(response=as.numeric(as.factor(validate_df[,outcome_name]))-1,
predictor=validate_predictions_known[,2])
plot(auc_rf, print.thres = "best", main=paste('AUC:',round(auc_rf$auc[[1]],3)))
abline(h=1,col='blue')
abline(h=0,col='green')
train_df_auto <- train_df[err$Reconstruction.MSE >= 0.1,]
set.seed(1234)
rf_model <- randomForest(x=train_df_auto[,feature_names],
y=as.factor(train_df_auto[,outcome_name]),
importance=TRUE, ntree=20, mtry = 3)
validate_predictions_unknown <- predict(rf_model, newdata=validate_df[,feature_names], type="prob")
auc_rf = roc(response=as.numeric(as.factor(validate_df[,outcome_name]))-1,
predictor=validate_predictions_unknown[,2])
plot(auc_rf, print.thres = "best", main=paste('AUC:',round(auc_rf$auc[[1]],3)))
abline(h=1,col='blue')
abline(h=0,col='green')
valid_all <- (validate_predictions_known[,2] + validate_predictions_unknown[,2]) / 2
auc_rf = roc(response=as.numeric(as.factor(validate_df[,outcome_name]))-1,
predictor=valid_all)
plot(auc_rf, print.thres = "best", main=paste('AUC:',round(auc_rf$auc[[1]],3)))
abline(h=1,col='blue')
abline(h=0,col='green')
graphics.off()
update.packages("glinternet")
library(glinternet)
