<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Hierarchical Bayesian Modeling of Decision-Making Tasks — hBayesDM-package • hBayesDM</title>

<!-- jquery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
<!-- Bootstrap -->

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha256-916EbMg70RQy9LHiGkXzG8hSg9EdNy97GazNG/aiY1w=" crossorigin="anonymous" />
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script>

<!-- sticky kit -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script>



<meta property="og:title" content="Hierarchical Bayesian Modeling of Decision-Making Tasks — hBayesDM-package" />

<meta property="og:description" content="Fit an array of decision-making tasks with computational models in a hierarchical Bayesian framework. Can perform hierarchical Bayesian analysis of various computational models with a single line of coding.
Bolded tasks, followed by their respective models, are itemized below.

 Bandit2-Armed Bandit (Rescorla-Wagner (delta)) --- bandit2arm_delta 
                        4-Armed Bandit with fictive updating + reward/punishment sensitvity (Rescorla-Wagner (delta)) --- bandit4arm_4par 
                        4-Armed Bandit with fictive updating + reward/punishment sensitvity + lapse (Rescorla-Wagner (delta)) --- bandit4arm_lapse
 Bandit2Kalman filter --- bandit4arm2_kalman_filter
 Choice RTDrift Diffusion Model --- choiceRT_ddm 
                           Drift Diffusion Model for a single subject --- choiceRT_ddm_single 
                           Linear Ballistic Accumulator (LBA) model --- choiceRT_lba 
                           Linear Ballistic Accumulator (LBA) model for a single subject --- choiceRT_lba_single
 Choice under Risk and AmbiguityExponential model --- cra_exp 
                                                 Linear model --- cra_linear
 Description-Based Decision Makingprobability weight function --- dbdm_prob_weight
 Delay DiscountingConstant Sensitivity --- dd_cs 
                                   Constant Sensitivity for a single subject --- dd_cs_single 
                                   Exponential --- dd_exp 
                                   Hyperbolic --- dd_hyperbolic 
                                   Hyperbolic for a single subject --- dd_hyperbolic_single
 Orthogonalized Go/NogoRW + Noise --- gng_m1 
                                        RW + Noise + Bias --- gng_m2 
                                        RW + Noise + Bias + Pavlovian Bias --- gng_m3 
                                        RW(modified) + Noise + Bias + Pavlovian Bias --- gng_m4
 Iowa GamblingOutcome-Representation Learning --- igt_orl 
                               Prospect Valence Learning-DecayRI --- igt_pvl_decay 
                               Prospect Valence Learning-Delta --- igt_pvl_delta 
                               Value-Plus_Perseverance --- igt_vpp
 Peer influence taskOCU model --- peer_ocu
 Probabilistic Reversal LearningExperience-Weighted Attraction --- prl_ewa 
                                                 Fictitious Update --- prl_fictitious 
                                                 Fictitious Update w/o alpha (indecision point) --- prl_fictitious_woa 
                                                 Fictitious Update and multiple blocks per subject --- prl_fictitious_multipleB 
                                                 Reward-Punishment --- prl_rp 
                                                 Reward-Punishment and multiple blocks per subject --- prl_rp_multipleB 
                                                 Fictitious Update with separate learning for Reward-Punishment --- prl_fictitious_rp 
                                                 Fictitious Update with separate learning for Reward-Punishment w/o alpha (indecision point) --- prl_fictitious_rp_woa
 Probabilistic Selection TaskQ-learning with two learning rates --- pst_gainloss_Q
 Risk AversionProspect Theory (PT) --- ra_prospect 
                               PT without a loss aversion parameter --- ra_noLA 
                               PT without a risk aversion parameter --- ra_noRA
 Risky Decision TaskHappiness model --- rdt_happiness
 Two-Step taskFull model (7 parameters) --- ts_par7 
                               6 parameter model (without eligibility trace, lambda) --- ts_par6 
                               4 parameter model --- ts_par4
 Ultimatum GameIdeal Bayesian Observer --- ug_bayes 
                                Rescorla-Wagner (delta) --- ug_delta" />

<meta property="og:description" content="" />
<meta name="twitter:card" content="summary" />



<!-- mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->


  </head>

  <body>
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">hBayesDM</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">1.0.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
      
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/CCS-Lab/hBayesDM">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Hierarchical Bayesian Modeling of Decision-Making Tasks</h1>
    <small class="dont-index">Source: <a href='https://github.com/CCS-Lab/hBayesDM/blob/master/R/hBayesDM.R'><code>R/hBayesDM.R</code></a></small>
    <div class="hidden name"><code>hBayesDM-package.Rd</code></div>
    </div>

    <div class="ref-description">
    
    <p>Fit an array of decision-making tasks with computational models in a hierarchical Bayesian framework. Can perform hierarchical Bayesian analysis of various computational models with a single line of coding.
Bolded tasks, followed by their respective models, are itemized below.</p>
<dl class='dl-horizontal'>
 <dt><strong>Bandit</strong></dt><dd><p>2-Armed Bandit (Rescorla-Wagner (delta)) --- <a href='bandit2arm_delta.html'>bandit2arm_delta</a> <br />
                        4-Armed Bandit with fictive updating + reward/punishment sensitvity (Rescorla-Wagner (delta)) --- <a href='bandit4arm_4par.html'>bandit4arm_4par</a> <br />
                        4-Armed Bandit with fictive updating + reward/punishment sensitvity + lapse (Rescorla-Wagner (delta)) --- <a href='bandit4arm_lapse.html'>bandit4arm_lapse</a></p></dd>
 <dt><strong>Bandit2</strong></dt><dd><p>Kalman filter --- <a href='bandit4arm2_kalman_filter.html'>bandit4arm2_kalman_filter</a></p></dd>
 <dt><strong>Choice RT</strong></dt><dd><p>Drift Diffusion Model --- <a href='choiceRT_ddm.html'>choiceRT_ddm</a> <br />
                           Drift Diffusion Model for a single subject --- <a href='choiceRT_ddm_single.html'>choiceRT_ddm_single</a> <br />
                           Linear Ballistic Accumulator (LBA) model --- <a href='choiceRT_lba.html'>choiceRT_lba</a> <br />
                           Linear Ballistic Accumulator (LBA) model for a single subject --- <a href='choiceRT_lba_single.html'>choiceRT_lba_single</a></p></dd>
 <dt><strong>Choice under Risk and Ambiguity</strong></dt><dd><p>Exponential model --- <a href='cra_exp.html'>cra_exp</a> <br />
                                                 Linear model --- <a href='cra_linear.html'>cra_linear</a></p></dd>
 <dt><strong>Description-Based Decision Making</strong></dt><dd><p>probability weight function --- <a href='dbdm_prob_weight.html'>dbdm_prob_weight</a></p></dd>
 <dt><strong>Delay Discounting</strong></dt><dd><p>Constant Sensitivity --- <a href='dd_cs.html'>dd_cs</a> <br />
                                   Constant Sensitivity for a single subject --- <a href='dd_cs_single.html'>dd_cs_single</a> <br />
                                   Exponential --- <a href='dd_exp.html'>dd_exp</a> <br />
                                   Hyperbolic --- <a href='dd_hyperbolic.html'>dd_hyperbolic</a> <br />
                                   Hyperbolic for a single subject --- <a href='dd_hyperbolic_single.html'>dd_hyperbolic_single</a></p></dd>
 <dt><strong>Orthogonalized Go/Nogo</strong></dt><dd><p>RW + Noise --- <a href='gng_m1.html'>gng_m1</a> <br />
                                        RW + Noise + Bias --- <a href='gng_m2.html'>gng_m2</a> <br />
                                        RW + Noise + Bias + Pavlovian Bias --- <a href='gng_m3.html'>gng_m3</a> <br />
                                        RW(modified) + Noise + Bias + Pavlovian Bias --- <a href='gng_m4.html'>gng_m4</a></p></dd>
 <dt><strong>Iowa Gambling</strong></dt><dd><p>Outcome-Representation Learning --- <a href='igt_orl.html'>igt_orl</a> <br />
                               Prospect Valence Learning-DecayRI --- <a href='igt_pvl_decay.html'>igt_pvl_decay</a> <br />
                               Prospect Valence Learning-Delta --- <a href='igt_pvl_delta.html'>igt_pvl_delta</a> <br />
                               Value-Plus_Perseverance --- <a href='igt_vpp.html'>igt_vpp</a></p></dd>
 <dt><strong>Peer influence task</strong></dt><dd><p>OCU model --- <a href='peer_ocu.html'>peer_ocu</a></p></dd>
 <dt><strong>Probabilistic Reversal Learning</strong></dt><dd><p>Experience-Weighted Attraction --- <a href='prl_ewa.html'>prl_ewa</a> <br />
                                                 Fictitious Update --- <a href='prl_fictitious.html'>prl_fictitious</a> <br />
                                                 Fictitious Update w/o alpha (indecision point) --- <a href='prl_fictitious_woa.html'>prl_fictitious_woa</a> <br />
                                                 Fictitious Update and multiple blocks per subject --- <a href='prl_fictitious_multipleB.html'>prl_fictitious_multipleB</a> <br />
                                                 Reward-Punishment --- <a href='prl_rp.html'>prl_rp</a> <br />
                                                 Reward-Punishment and multiple blocks per subject --- <a href='prl_rp_multipleB.html'>prl_rp_multipleB</a> <br />
                                                 Fictitious Update with separate learning for Reward-Punishment --- <a href='prl_fictitious_rp.html'>prl_fictitious_rp</a> <br />
                                                 Fictitious Update with separate learning for Reward-Punishment w/o alpha (indecision point) --- <a href='prl_fictitious_rp_woa.html'>prl_fictitious_rp_woa</a></p></dd>
 <dt><strong>Probabilistic Selection Task</strong></dt><dd><p>Q-learning with two learning rates --- <a href='pst_gainloss_Q.html'>pst_gainloss_Q</a></p></dd>
 <dt><strong>Risk Aversion</strong></dt><dd><p>Prospect Theory (PT) --- <a href='ra_prospect.html'>ra_prospect</a> <br />
                               PT without a loss aversion parameter --- <a href='ra_noLA.html'>ra_noLA</a> <br />
                               PT without a risk aversion parameter --- <a href='ra_noRA.html'>ra_noRA</a></p></dd>
 <dt><strong>Risky Decision Task</strong></dt><dd><p>Happiness model --- <a href='rdt_happiness.html'>rdt_happiness</a></p></dd>
 <dt><strong>Two-Step task</strong></dt><dd><p>Full model (7 parameters) --- <a href='ts_par7.html'>ts_par7</a> <br />
                               6 parameter model (without eligibility trace, lambda) --- <a href='ts_par6.html'>ts_par6</a> <br />
                               4 parameter model --- <a href='ts_par4.html'>ts_par4</a></p></dd>
 <dt><strong>Ultimatum Game</strong></dt><dd><p>Ideal Bayesian Observer --- <a href='ug_bayes.html'>ug_bayes</a> <br />
                                Rescorla-Wagner (delta) --- <a href='ug_delta.html'>ug_delta</a></p></dd>

    </dl>
    
    </div>

        
    <h2 class="hasAnchor" id="references"><a class="anchor" href="#references"></a>References</h2>

    <p>Please cite as:
Ahn, W.-Y., Haines, N., &amp; Zhang, L. (2017). Revealing neuro-computational mechanisms of reinforcement learning and decision-making with the hBayesDM package. <em>Computational Psychiatry</em>. 1, 24-57. https://doi.org/10.1162/CPSY_a_00002</p>
    
    <h2 class="hasAnchor" id="see-also"><a class="anchor" href="#see-also"></a>See also</h2>

    <div class='dont-index'><p>For tutorials and further readings, visit : <a href='http://rpubs.com/CCSL/hBayesDM'>http://rpubs.com/CCSL/hBayesDM</a>.</p></div>
    

  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      
      <li><a href="#references">References</a></li>

      <li><a href="#see-also">See also</a></li>
          </ul>

    <h2>Author</h2>
    <p>Woo-Young Ahn <a href='mailto:wahn55@snu.ac.kr'>wahn55@snu.ac.kr</a></p>
<p>Nathaniel Haines <a href='mailto:haines.175@osu.edu'>haines.175@osu.edu</a></p>
<p>Lei Zhang <a href='mailto:bnuzhanglei2008@gmail.com'>bnuzhanglei2008@gmail.com</a></p>
  </div>
</div>

      <footer>
      <div class="copyright">
  <p>Developed by Woo-Young Ahn, Nate Haines, Lei Zhang.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.3.0.</p>
</div>
      </footer>
   </div>

  

  </body>
</html>

